description = "Decompose project into Conductor tracks with architecture research, cross-cutting constraints, and dependency-aware sequencing"
prompt = """
# /architect-decompose

You are performing full project decomposition for Conductor. This is the primary Architect command. It reads Conductor's project files, performs architecture research, identifies cross-cutting concerns, generates a complete system architecture, and produces fully sequenced implementation tracks.

Run this once after `/conductor:setup`. Re-run after major pivots.

---

## Context Optimization Strategy

This command uses **sub-agent dispatch** for architecture research (reference file reading, codebase exploration) to keep the orchestrator's context lean. The orchestrator generates track briefs **directly** — brief fidelity requires full context and the token cost is justified.

**Platform detection:** If the Task tool is available (Claude Code), spawn pattern-matcher and codebase-analyzer sub-agents in parallel during Step 3. Briefs are always generated by the orchestrator (Step 5). For very large projects (25+ tracks), brief-generator sub-agents are available as a fallback.

---

## Step 1: Pre-Flight Checks

1. **Check for Conductor directory:**
   ```
   ls conductor/
   ```
   If `conductor/` does not exist, stop and tell the user:
   "Run /conductor:setup first. Architect reads Conductor's product.md and tech-stack.md as input."

2. **Run compatibility check:**
   ```bash
   python ${extensionPath}/scripts/check_conductor_compat.py
   ```
   - If it reports missing required files, stop and tell the user which files are needed.
   - If it reports warnings, note them but continue.
   - If it detects an existing ARCHITECT:HOOKS marker, warn: "Architect hooks already installed. This will regenerate architecture and track briefs."

3. **Read Conductor files:**
   - `conductor/product.md` (required)
   - `conductor/tech-stack.md` (required)
   - `conductor/workflow.md` (required)
   - `conductor/product-guidelines.md` (if exists)

4. **Check for existing architect/ directory:**
   - If `architect/` exists, this is a re-run. Notify the user and ask whether to regenerate from scratch or do an incremental update. For incremental: read existing architecture.md, cross-cutting.md, and track states to preserve completed work.

---

## Step 2: Gap Analysis

Review all Conductor files and identify what you know vs. what is missing. Ask the developer ONLY for information that is genuinely missing and necessary for decomposition.

**Ask about (if not already covered in product.md / tech-stack.md):**

1. **Key user workflows** — "What are the 3-5 most important things a user does in this system?" (Only ask if product.md lacks clear user flows)
2. **Scale and performance constraints** — "Any specific throughput, latency, or data volume requirements?" (Only ask if not mentioned)
3. **Existing system integrations** — "Does this integrate with any existing systems, APIs, or databases?" (Only ask if not mentioned)
4. **Deployment environment** — "Where will this run? (cloud provider, Kubernetes, bare metal, etc.)" (Only ask if tech-stack.md is silent on deployment)

Do NOT ask about things already covered in the Conductor files. Summarize what you learned from the files to confirm understanding before proceeding.

---

## Step 3: Architecture Research (Context-Optimized)

This is where Architect adds unique value. You identify patterns the developer may not have considered.

### 3a. Extract Signals (Orchestrator — lightweight)

Read ALL project inputs (product.md, tech-stack.md, developer answers, product-guidelines.md) and extract architectural signals — phrases, requirements, or characteristics that imply specific patterns.

List the signals you found. Example:
```
Signals extracted:
- "workflows span multiple services" + "rollback on failure" → Saga pattern
- "events published after DB writes" → Transactional Outbox
- "multiple services" + "debugging production" → Distributed Tracing
- "external API calls" to payment provider → Circuit Breaker
```

### 3b. Dispatch Research Sub-Agents

**Parallel execution (if Task tool is available — Claude Code):**

Spawn the following sub-agents IN PARALLEL using the Task tool:

1. **pattern-matcher** (agent: `${extensionPath}/agents/pattern-matcher.md`):
   - Input: The extracted signals from Step 3a, plus tech stack summary
   - Returns: Structured pattern matches with tiers + cross-cutting concern evaluation

2. **codebase-analyzer** (agent: `${extensionPath}/agents/codebase-analyzer.md`):
   - Input: Project root path + tech stack summary from tech-stack.md
   - Returns: Structured codebase map with components, dependencies, and architectural signals

Wait for both sub-agents to return their structured summaries.

**Sequential fallback (if Task tool is unavailable — Gemini CLI):**

Perform these steps sequentially in the current context:

1. Read the reference files:
   - `${extensionPath}/skills/architect/references/architecture-patterns.md`
   - `${extensionPath}/skills/architect/references/cross-cutting-catalog.md`

2. For each signal, look up matching patterns in architecture-patterns.md. Verify:
   - Do the signals genuinely match? (Avoid false positives)
   - Is the "when NOT to use" applicable here?
   - What tier does it fall into given signal strength?

3. Walk through the cross-cutting catalog:
   - Evaluate EVERY item in the "Always" section
   - Evaluate "If multi-service" items if architecture has 2+ services
   - Evaluate "If user-facing" items if end users interact with the system
   - Evaluate "If data-heavy" items if significant data persistence is involved

4. Explore the codebase to map structure, components, and dependencies.

### 3c. Synthesize Results

Combine the sub-agent summaries (or sequential results) into a unified recommendation set. Merge any overlapping signals from the codebase analysis with the pattern matching results.

### 3d. Research (if tools available)

Check which research tools are available and use them to enrich recommendations:

1. **Context7 MCP** (if configured) — Look up implementation specifics for the project's tech stack
2. **Web search** (if available) — Compare current best practices
3. **Deep Research skill** (if configured) — For complex decisions with many viable options
4. **Existing skills/plugins** — Check if relevant skills already exist before planning to build

If no external tools are available, the built-in knowledge base is sufficient for solid recommendations.

### 3e. Present Recommendations

Present pattern recommendations to the developer in three tiers:

**Strongly Recommended** (system needs these — multiple strong signal matches):
For each: pattern name, why it matches (cite specific signals), trade-offs summary, implementation approach for this tech stack.

**Recommended** (will save pain later — single strong signal match):
For each: pattern name, why it matches, trade-offs, what happens if you skip it.

**Consider for Later** (may emerge during implementation — inferred signals):
For each: pattern name, the signal that suggests it, the measurable trigger that would confirm it's needed.

### 3f. Developer Accepts/Rejects/Modifies

For each recommendation, the developer can:
- **Accept** — Pattern becomes part of the architecture
- **Reject** — Note the rejection reason in an ADR
- **Modify** — Adjust the approach (e.g., "use Redis Streams instead of Kafka")
- **Defer** — Move to "Consider for Later" with a trigger condition

Wait for developer input before proceeding.

### REVIEW GATE 1: Architecture Research Approval
Confirm: "These are the accepted patterns and cross-cutting concerns. Ready to generate the architecture?"

---

## Step 4: Generate Architecture (Write-to-Disk, Summarize-Back)

Read templates from `${extensionPath}/skills/architect/templates/` and generate the architecture artifacts.

**Context optimization:** Write each artifact directly to disk. Keep only a ONE-LINE SUMMARY of each artifact in the conversation. Do NOT keep the full artifact content in context after writing.

### 4a. Create architect/ directory structure
```
mkdir -p architect/hooks architect/discovery/pending architect/discovery/processed architect/references
```

### 4b. Generate architect/architecture.md
Using template: `${extensionPath}/skills/architect/templates/architecture.md`

Include:
- System overview (from product.md + gap analysis)
- Component map (ASCII diagram showing all components and connections)
- Technology decisions table (key choices with rationale)
- ADRs for each significant decision (accepted AND rejected patterns)
- Accepted patterns table with tiers
- Deferred pattern triggers (for "Consider for Later" patterns)

Write to disk, then report: `"Generated architecture.md — [N] components, [N] ADRs, [N] accepted patterns"`

### 4c. Generate architect/cross-cutting.md
Using template: `${extensionPath}/skills/architect/templates/cross-cutting.md`

Walk through the cross-cutting evaluation results (from Step 3). For each applicable item, write a concrete constraint (not generic). Example:
- Good: "structlog for Python, JSON format, trace_id in every log line"
- Bad: "use structured logging"

Tag as v1 (Wave 1).

Write to disk, then report: `"Generated cross-cutting.md — [N] constraints in v1"`

### 4d. Generate architect/interfaces.md
Using template: `${extensionPath}/skills/architect/templates/interfaces.md`

Define track-to-track contracts:
- REST endpoints: method, path, request/response schemas, auth requirements
- Event contracts: event name, payload schema, when published
- Shared data schemas: field names, types, owned-by

Write to disk, then report: `"Generated interfaces.md — [N] endpoints, [N] event contracts"`

### 4e. Generate architect/dependency-graph.md
Using template: `${extensionPath}/skills/architect/templates/dependency-graph.md`

Build the DAG from the track list. Validate with:
```bash
python ${extensionPath}/scripts/validate_dag.py --tracks-dir conductor/tracks
```

If cycles detected, restructure until the graph is acyclic.

Write to disk, then report: `"Generated dependency-graph.md — [N] tracks, [N] edges, 0 cycles"`

### 4f. Generate architect/execution-sequence.md
Using template: `${extensionPath}/skills/architect/templates/execution-sequence.md`

Run topological sort:
```bash
python ${extensionPath}/scripts/topological_sort.py --tracks-dir conductor/tracks
```

Write wave-by-wave sequence with completion criteria per wave.

Write to disk, then report: `"Generated execution-sequence.md — [N] waves"`

### Summary after Step 4

Present the collected one-line summaries to the developer:
```
Architecture artifacts generated:
- architecture.md — 4 components, 3 ADRs, 2 accepted patterns
- cross-cutting.md — 12 constraints in v1
- interfaces.md — 8 endpoints, 3 event contracts
- dependency-graph.md — 15 tracks, 22 edges, 0 cycles
- execution-sequence.md — 4 waves
```

### REVIEW GATE 2: Architecture Approval
Present the architecture summary to the developer. They can read any artifact from disk for details.

Ask: "Does this architecture look right? Any changes before I generate track briefs?"

Wait for developer approval before proceeding.

### 4g. Extract and Map ALL Requirements from product.md

**CRITICAL: Re-read `conductor/product.md` now.** Do not rely on memory from Step 1 — context may have been compacted. Read the file fresh.

Walk through EVERY section of product.md. For each statement that contains:
- **Specific numbers** — throughput, capacity, timeout values, size limits, counts
- **Acceptance criteria** — what "done" looks like, success conditions
- **Boundary conditions** — edge cases, error handling, limits, constraints
- **User expectations** — behavioral requirements, workflow requirements
- **Non-functional requirements** — performance, security, reliability, compliance

Extract it verbatim (not paraphrased) and map it to one or more tracks.

Output TWO artifacts:

**1. Per-track requirements mapping** (JSON) — write to `architect/requirements-map.json`:
```json
{
  "03_auth": [
    "Session timeout: 30 min inactivity",
    "Max 5 failed login attempts before lockout",
    "Support both JWT and API key authentication"
  ],
  "04_workflow_engine": [
    "Up to 50 steps per workflow",
    "100 concurrent workflow executions at MVP",
    "Step timeout: 5 minutes",
    "Support parallel step execution and conditional branching"
  ]
}
```

**2. Coverage checklist** — list ALL extracted requirements with their track mapping:
```
[x] "Up to 50 steps per workflow" → 04_workflow_engine
[x] "100 concurrent workflow executions" → 04_workflow_engine, 01_infra
[x] "Session timeout: 30 min" → 03_auth
[ ] "API p99 latency < 100ms" → UNMAPPED — needs assignment
```

If ANY requirement is UNMAPPED, assign it to the most relevant track before proceeding. Every requirement MUST be mapped to at least one track. Cross-cutting requirements that apply to all tracks should be mapped to the cross-cutting.md file AND to each affected track.

**Guidelines:**
- Extract verbatim — do not summarize or paraphrase
- Include ALL requirements, not just 3-8 per track — completeness over conciseness
- Requirements spanning multiple tracks: include in each
- Do NOT omit requirements "already in cross-cutting.md" — include them anyway for traceability

---

## Step 5: Generate Track Briefs (Orchestrator-Direct)

> **Critical: Brief vs Spec**
>
> You are generating BRIEFS, not specs. A brief tells Conductor what the track
> is about and what to ask the developer. It does NOT make design decisions.
>
> WRONG (making decisions):
>   "Use SQLAlchemy 2.0 async with Alembic for migrations"
>   "Spawn the user's default shell by reading $SHELL"
>   "FR-1: Dedicated reader thread performs blocking read()..."
>
> RIGHT (identifying the decision):
>   "ORM/migration strategy: SQLAlchemy sync vs async? Alembic vs raw SQL?"
>   "Shell spawning: $SHELL vs hardcoded path? Fallback on missing shell?"
>   "Threading model: dedicated reader vs async I/O? Reader-only vs reader+writer?"
>
> WRONG (writing implementation plans):
>   Phase 1: Set up Alembic, create initial migration, define models...
>
> RIGHT (estimating scope):
>   Complexity: M
>   Estimated Phases: ~3
>
> The developer makes design choices when Conductor asks them during implementation.
> Your job is to identify WHAT needs deciding, not to decide it.

### 5a. Prepare Context Bundles

For each track in execution sequence order, run `prepare_brief_context.py`. On first generation (when `metadata.json` does not yet exist), pass track details via CLI arguments:

```bash
python ${extensionPath}/scripts/prepare_brief_context.py \
    --track <track_id> \
    --tracks-dir conductor/tracks \
    --architect-dir architect \
    --track-name "<human readable name>" \
    --wave <N> \
    --complexity <S|M|L|XL> \
    --description "<one-line description>" \
    --dependencies <dep_track_id> ... \
    --interfaces-owned "<interface>" ... \
    --interfaces-consumed "<interface>" ... \
    --events-published "<event>" ... \
    --events-consumed "<event>" ... \
    --requirements "<req1>" "<req2>" ... \
    --product-md-path conductor/product.md
```

The `--requirements` values come from the per-track requirements extracted in Step 4g. Pass each requirement as a separate quoted string.

On subsequent runs (when `metadata.json` exists), the CLI overrides can be omitted — the script reads from the file:
```bash
python ${extensionPath}/scripts/prepare_brief_context.py --track <track_id> --tracks-dir conductor/tracks --architect-dir architect
```

This produces a filtered JSON context bundle containing only the constraints, interfaces, dependencies, and architecture excerpt relevant to that specific track.

### 5b. Generate Briefs (Orchestrator-Direct)

**You generate all briefs yourself, sequentially, in execution sequence order.** This ensures every brief has full access to product.md, architecture.md, cross-cutting.md, interfaces.md, and the complete per-track requirements mapping from Step 4g.

> **Why not sub-agents?** Brief quality depends on the plan's fidelity. The orchestrator is the only entity with the full context — product.md, architecture decisions, cross-cutting constraints, interface contracts, AND the judgment to know which details matter. Delegating to isolated sub-agents risks diluting the plan. The token cost (~15-30K extra for a 15-track project on a 200K window) is trivially justified.

For each track in execution sequence order:

1. **Re-read the track's requirements** from the Step 4g mapping (in `architect/requirements-map.json`)
2. **Read the relevant architecture excerpt** from `architect/architecture.md` — find the section about this track's component
3. **Read the applicable constraints** from `architect/cross-cutting.md`
4. **Read the interface contracts** from `architect/interfaces.md` — endpoints this track owns and consumes
5. **Read template:** `${extensionPath}/skills/architect/templates/track-brief.md`
6. **Run context header generator:**
   ```bash
   python ${extensionPath}/scripts/inject_context.py --track <track_id> --tracks-dir conductor/tracks --architect-dir architect
   ```
   (Write preliminary metadata.json first if it doesn't exist)

7. **Enrich with web search** (if available): Search for implementation patterns specific to this track's tech + requirements. For example:
   - Auth track → "FastAPI JWT middleware best practices"
   - Workflow track → "Celery canvas DAG execution timeout handling"
   - Database track → "SQLAlchemy async session factory patterns"
   Include 2-3 relevant findings in the Enriched Context section.

8. **Generate brief.md** — the enriched track specification:

   - **Source Requirements** — VERBATIM requirements from product.md mapped to this track in Step 4g. Every requirement listed. Not summaries.
   - **Cross-Cutting Constraints** — ALL applicable constraints (no truncation)
   - **Interface Contracts** — exact endpoints/events this track owns and consumes, with schemas from interfaces.md
   - **Dependencies** — track-level dependencies with what is needed from each
   - **What This Track Delivers** — one paragraph grounded in the requirements
   - **Scope IN** — concrete boundaries. EACH requirement from Source Requirements must have a corresponding scope item.
   - **Scope OUT** — what's excluded with pointers to where it lives
   - **Key Design Decisions** — 3-7 genuine design forks with options and trade-offs. QUESTIONS, not answers. Grounded in the specific requirements (e.g., "50 steps per workflow" raises the question of step execution model).
   - **Architectural Notes** — integration points, cross-track impacts, gotchas from architecture. Enriched with web search findings if available.
   - **Enriched Context** — implementation patterns and best practices from web search (if available). Technology-specific guidance for this track's stack + requirements.
   - **Test Strategy** — framework, unit/integration breakdown, prerequisites, coverage threshold, key scenarios
   - **Complexity** — S/M/L/XL
   - **Estimated Phases** — advisory count

9. **Write** `conductor/tracks/<track_id>/brief.md`
10. **Generate and write** `conductor/tracks/<track_id>/metadata.json` using template:
    - Read template: `${extensionPath}/skills/architect/templates/track-metadata.json`
    - Fill in: track_id, status ("new"), complexity (S/M/L/XL), wave, cc_version_at_brief (v1), cc_version_current (v1), dependencies, interfaces_owned, interfaces_consumed, created_at (ISO 8601 timestamp)
    - Include the full requirements list in the `requirements` field.
    - Note: `test_command` and `test_timeout_seconds` are NOT set here. Conductor adds these when it generates the implementation plan.
11. **Summarize:** Report one-line summary for this track.

Repeat for all tracks. Write-to-disk, summarize-back: after writing each brief, keep only the one-line summary in context.

**Fallback for very large projects (25+ tracks):**
If the project has 25+ tracks and the orchestrator's context is genuinely at risk, fall back to dispatching brief-generator sub-agents (agent: `${extensionPath}/agents/brief-generator.md`) in batches of 3-5. Pass the FULL per-track requirements (not a compressed bundle) via a JSON file written to disk:
```bash
# Write requirements to disk for each track (avoids CLI escaping issues)
# The requirements.json contains the full array from architect/requirements-map.json for this track
```
Then pass the file path to the sub-agent. The sub-agent reads the file directly.

**Do NOT generate spec.md or plan.md.** Conductor generates these interactively with the developer during `/conductor:implement`.

### 5c. Update conductor/tracks.md

After generating all tracks, update (or create) `conductor/tracks.md` as the track registry. Use Conductor's expected format — each track as a section with checkbox status:

```markdown
# Project Tracks

> Generated by Architect. {N} tracks across {M} waves.
> Run /conductor:implement to begin.

---

## [ ] Track: {track_name}
- **ID:** {track_id}
- **Wave:** {wave_number}
- **Complexity:** {S|M|L|XL}
- **Dependencies:** {comma-separated dependency IDs, or "None"}

---

## [ ] Track: {next_track_name}
...
```

**Status checkbox mapping (Conductor convention):**
- `[ ]` = not started (Architect always writes this)
- `[~]` = in progress (set by Conductor during implementation)
- `[x]` = complete (set by Conductor after all phases done)

Architect ONLY writes `[ ]`. Conductor manages all status transitions.

### 5d. Present Track Summary

Collect the one-line summaries from brief generation and present:

```
Track briefs generated:
- 01_infra_scaffold — Wave 1, Complexity M, 4 design decisions
- 02_data_models — Wave 1, Complexity L, 6 design decisions
- 03_auth — Wave 2, Complexity M, 5 design decisions
- ...

Total: [N] tracks across [N] waves
Complexity distribution: [N]×S, [N]×M, [N]×L, [N]×XL
```

### 5e. Validate Requirements Coverage

Run the requirements validation script:
```bash
python ${extensionPath}/scripts/validate_requirements.py \
    --product-md conductor/product.md \
    --tracks-dir conductor/tracks \
    --requirements-map architect/requirements-map.json
```

This script checks that:
1. Every requirement extracted in Step 4g appears in at least one track's brief.md Source Requirements section
2. Every requirement in a track's Source Requirements has a corresponding Scope IN item
3. No requirements from product.md were missed in Step 4g extraction

Present the coverage report to the developer:
```
Requirements Coverage Report:
  Total requirements extracted: 47
  Mapped to tracks: 47/47 (100%)
  Present in briefs: 47/47 (100%)
  Scope coverage: 45/47 (95.7%)

  GAPS (requirements in brief but not in Scope IN):
  - Track 03_auth: "Support API key rotation" — not in Scope IN
  - Track 06_events: "Dead letter queue for failed events" — not in Scope IN
```

If coverage is below 100%, fix the gaps before proceeding to Review Gate 3.

### REVIEW GATE 3: Track Brief Approval
Present the track list summary to the developer:
- Total track count and complexity distribution
- Wave assignments
- Key dependencies
- Estimated effort shape (which waves are heaviest)
- For each track: one-line scope summary and count of key design decisions
- Requirements coverage report from Step 5e

Ask: "These are the track briefs. Any adjustments before I finalize?"

Wait for approval. Then confirm all brief and metadata files have been written.

---

## Step 6: Install Hooks

### 6a. Copy hook files to project
Copy all files from `${extensionPath}/hooks/project-hooks/` to `architect/hooks/`:
```
architect/hooks/README.md
architect/hooks/01-constraint-update-check.md
architect/hooks/02-interface-verification.md
architect/hooks/03-discovery-check.md
architect/hooks/04-phase-validation.md
architect/hooks/05-wave-sync.md
```

### 6b. Inject deferred pattern triggers
In `architect/hooks/03-discovery-check.md`, append the "Consider for Later" patterns and their measurable trigger thresholds from Step 3.

### 6c. Add workflow marker
Add this marker line to `conductor/workflow.md` (at the end, before any closing markers):
```markdown
<!-- ARCHITECT:HOOKS — Read architect/hooks/*.md for additional workflow steps -->
```

### 6d. Copy references to project
Copy `${extensionPath}/skills/architect/references/` to `architect/references/` so the implementing agent has the knowledge base available without the plugin installed.

### 6e. Initialize discovery directory
Create:
```
architect/discovery/pending/     (empty)
architect/discovery/processed/   (empty)
architect/discovery/discovery-log.md  (header only)
```

---

## Step 7: Final Summary

Present a complete summary:
- Number of track briefs generated, grouped by wave
- Total complexity weight
- Architecture patterns adopted
- Cross-cutting constraints (v1)
- Number of interfaces defined
- Hook installation status

Tell the developer: "Architecture and track briefs are ready. Start implementation with `/conductor:implement` on Wave 1 tracks. Conductor will read each brief and guide you through interactive spec and plan generation. The hooks in architect/hooks/ will guide cross-cutting compliance and discovery during implementation."

---

## Re-Run Mode (After Pivot)

If `architect/` already exists and tracks are in various states, classify each:

| Track State | Affected by Pivot? | Action |
|-------------|-------------------|--------|
| completed | No | FREEZE — no changes |
| completed | Yes | Generate patch phase in plan.md (Conductor already generated it) |
| in_progress | No | FREEZE_AFTER_COMPLETION — let it finish |
| in_progress | Yes | PAUSE — present options to developer |
| new | Affected | REGENERATE — new brief.md |
| (new) | — | GENERATE — create brief.md from scratch |

Rebuild dependency graph around frozen tracks. Re-sequence waves.
"""
