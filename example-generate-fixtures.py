#!/usr/bin/env python3
"""Generate all test fixtures."""
import json
import os

BASE = "/home/claude/test-suite/fixtures"

def write(path, content):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w") as f:
        f.write(content)
    print(f"  ✓ {path}")

print("Creating fixtures...")

# ═══════════════════════════════════════════════════════════
# SCENARIO 1: Good Architect output
# ═══════════════════════════════════════════════════════════
A = f"{BASE}/architect-output"

write(f"{A}/tracks.md", """\
# Project Tracks

> Generated by Architect. 3 tracks across 2 waves.
> Run /conductor:implement to begin.

---

## [ ] Track: Infrastructure Scaffold
- **ID:** 01_infra_scaffold
- **Wave:** 1
- **Complexity:** M
- **Dependencies:** None

---

## [ ] Track: Authentication System
- **ID:** 02_auth_system
- **Wave:** 1
- **Complexity:** L
- **Dependencies:** None

---

## [ ] Track: Data Layer
- **ID:** 03_data_layer
- **Wave:** 2
- **Complexity:** XL
- **Dependencies:** 01_infra_scaffold

---
""")

# Track 01
write(f"{A}/tracks/01_infra_scaffold/metadata.json", json.dumps({
    "track_id": "01_infra_scaffold",
    "status": "new",
    "complexity": "M",
    "wave": 1,
    "cc_version_at_brief": "v1.0",
    "cc_version_current": "v1.0",
    "dependencies": [],
    "interfaces_owned": ["IInfraConfig"],
    "interfaces_consumed": [],
    "patches": [],
    "created_at": "2026-02-07T12:00:00Z",
    "started_at": None,
    "completed_at": None
}, indent=2))

write(f"{A}/tracks/01_infra_scaffold/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 01_infra_scaffold | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-03: Environment configuration via .env files, never hardcoded
## Interfaces
Owns: IInfraConfig (database connection, redis connection, env vars)
Consumes: None (Wave 1, no upstream dependencies)
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->

# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure, Docker Compose environment, database initialization, and CI/CD pipeline.

## Scope
IN:
- Docker Compose with PostgreSQL 16, Redis 7, and app service
- Database initialization scripts and migration framework
- Environment configuration (.env template + validation)
- CI/CD pipeline (GitHub Actions: lint, test, build)

OUT:
- Application code (handled by downstream tracks)
- Authentication (Track 02)

## Key Design Decisions
1. **Migration framework:** Alembic vs raw SQL migrations? Trade-off: ORM coupling vs explicit control.
2. **Docker strategy:** Single Dockerfile vs multi-stage? Trade-off: Build speed vs image size.
3. **CI provider:** GitHub Actions vs GitLab CI? Trade-off: Ecosystem integration vs self-hosting.
4. **Database pooling:** PgBouncer vs SQLAlchemy pool? Trade-off: External dependency vs simpler stack.

## Architectural Notes
- Track 03 depends on the database configuration this track establishes
- CI pipeline must be extensible for downstream tracks

## Complexity: M
## Estimated Phases: ~3
""")

# Track 02
write(f"{A}/tracks/02_auth_system/metadata.json", json.dumps({
    "track_id": "02_auth_system",
    "status": "new",
    "complexity": "L",
    "wave": 1,
    "cc_version_at_brief": "v1.0",
    "cc_version_current": "v1.0",
    "dependencies": [],
    "interfaces_owned": ["IAuth"],
    "interfaces_consumed": [],
    "patches": [],
    "created_at": "2026-02-07T12:00:00Z",
    "started_at": None,
    "completed_at": None
}, indent=2))

write(f"{A}/tracks/02_auth_system/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 02_auth_system | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-04: JWT-based authentication for all API endpoints
## Interfaces
Owns: IAuth (login, register, token refresh)
Consumes: None
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->

# Track 02: Authentication System

## What This Track Delivers
Implements JWT-based authentication with login, registration, and token management.

## Scope
IN:
- User model and password hashing
- JWT token generation and validation
- Login and registration endpoints

OUT:
- Role-based authorization (future track)
- OAuth2 social login (future track)

## Key Design Decisions
1. **Token storage:** Stateless JWT vs server-side sessions? Trade-off: Scalability vs revocation.
2. **Password hashing:** bcrypt vs argon2? Trade-off: Compatibility vs security margin.
3. **Refresh token strategy:** Rotating vs long-lived? Trade-off: Security vs complexity.

## Architectural Notes
- All downstream tracks consume IAuth for protected endpoints

## Complexity: L
## Estimated Phases: ~4
""")

# Track 03
write(f"{A}/tracks/03_data_layer/metadata.json", json.dumps({
    "track_id": "03_data_layer",
    "status": "new",
    "complexity": "XL",
    "wave": 2,
    "cc_version_at_brief": "v1.0",
    "cc_version_current": "v1.0",
    "dependencies": ["01_infra_scaffold"],
    "interfaces_owned": ["IDataAccess"],
    "interfaces_consumed": ["IInfraConfig"],
    "patches": [],
    "created_at": "2026-02-07T12:00:00Z",
    "started_at": None,
    "completed_at": None
}, indent=2))

write(f"{A}/tracks/03_data_layer/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 03_data_layer | Wave: 2 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-02: Repository pattern for all data access
## Interfaces
Owns: IDataAccess
Consumes: IInfraConfig (from Track 01)
## Dependencies
01_infra_scaffold
<!-- END ARCHITECT CONTEXT -->

# Track 03: Data Layer

## What This Track Delivers
Implements the data access layer using SQLAlchemy with repository pattern.

## Scope
IN:
- SQLAlchemy model base classes
- Repository pattern implementation
- Database migration scripts

OUT:
- Specific domain models (handled by feature tracks)

## Key Design Decisions
1. **ORM style:** Declarative vs imperative mapping? Trade-off: Simplicity vs flexibility.
2. **Repository granularity:** One repo per model vs shared base? Trade-off: Type safety vs DRY.
3. **Async support:** sync SQLAlchemy vs async? Trade-off: Simplicity vs performance.

## Architectural Notes
- Must use the database configuration from Track 01

## Complexity: XL
## Estimated Phases: ~5
""")

# ═══════════════════════════════════════════════════════════
# SCENARIO 2: Manual track (has spec+plan, no brief)
# ═══════════════════════════════════════════════════════════
M = f"{BASE}/conductor-manual"

write(f"{M}/tracks/99_manual_track/metadata.json", json.dumps({
    "track_id": "99_manual_track",
    "status": "new",
    "complexity": "S",
    "wave": 1,
    "dependencies": [],
    "interfaces_owned": [],
    "interfaces_consumed": [],
    "patches": [],
    "created_at": "2026-02-07T14:00:00Z",
    "started_at": None,
    "completed_at": None
}, indent=2))

write(f"{M}/tracks/99_manual_track/spec.md", """\
# Track 99: Manual Track

## Functional Requirements
- FR-1: Basic CRUD operations
- FR-2: Input validation
""")

write(f"{M}/tracks/99_manual_track/plan.md", """\
# Track 99: Manual Track — Implementation Plan

## Phase 1: Setup
- [ ] Task 1.1: Create module structure

## Phase 2: Implementation
- [ ] Task 2.1: Implement CRUD operations
""")

# ═══════════════════════════════════════════════════════════
# SCENARIO 3: Post spec-gen (brief + spec, testing preservation)
# ═══════════════════════════════════════════════════════════
P = f"{BASE}/post-spec-gen"

# Copy brief from architect-output
write(f"{P}/tracks/01_infra_scaffold/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 01_infra_scaffold | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-03: Environment configuration via .env files, never hardcoded
## Interfaces
Owns: IInfraConfig (database connection, redis connection, env vars)
Consumes: None (Wave 1, no upstream dependencies)
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->

# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure.

## Key Design Decisions
1. **Migration framework:** Alembic vs raw SQL?

## Complexity: M
## Estimated Phases: ~3
""")

# Spec WITH context header preserved (good output)
write(f"{P}/tracks/01_infra_scaffold/spec.md", """\
<!-- ARCHITECT CONTEXT | Track: 01_infra_scaffold | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-03: Environment configuration via .env files, never hardcoded
## Interfaces
Owns: IInfraConfig (database connection, redis connection, env vars)
Consumes: None (Wave 1, no upstream dependencies)
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->

# Track 01: Infrastructure Scaffold — Specification

## Design Decisions (Resolved)
1. Migration framework: **Alembic**
2. Docker strategy: **Multi-stage**

## Functional Requirements
- FR-1: Docker Compose with PostgreSQL 16, Redis 7, app service
- FR-2: Alembic migration framework
""")

# ═══════════════════════════════════════════════════════════
# SCENARIO 4: Bad fixtures (should FAIL validation)
# ═══════════════════════════════════════════════════════════
B = f"{BASE}/bad"

# Table format (old Architect output)
write(f"{B}/tracks_table_format.md", """\
# Track Registry

| ID | Name | Wave | Complexity | Status | Dependencies |
|----|------|------|------------|--------|-------------|
| 01_infra_scaffold | Infrastructure Scaffold | 1 | M | not started | — |
| 02_auth_system | Authentication System | 1 | L | not started | — |
""")

# Old metadata schema
write(f"{B}/metadata_old_schema.json", json.dumps({
    "track_id": "01_infra_scaffold",
    "state": "NOT_STARTED",
    "complexity": "M",
    "wave": 1,
    "dependencies": [],
    "created_at": "2026-02-07T12:00:00Z",
    "started_at": None,
    "completed_at": None
}, indent=2))

# Brief without ARCHITECT CONTEXT header
write(f"{B}/brief_no_context_header.md", """\
# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure.

## Scope
IN:
- Docker Compose setup

OUT:
- Application code

## Key Design Decisions
1. Migration framework: Alembic vs raw SQL?

## Complexity: M
## Estimated Phases: ~3
""")

# Spec WITHOUT context header (failed preservation)
write(f"{B}/spec_lost_context.md", """\
# Track 01: Infrastructure Scaffold — Specification

## Design Decisions (Resolved)
1. Migration framework: **Alembic**

## Functional Requirements
- FR-1: Docker Compose with PostgreSQL 16
""")

print("\nDone. All fixtures created.")
