#!/usr/bin/env python3
"""Generate all test fixtures for contract tests.

Creates fixture directories with known-good and known-bad files
for validating Conductor <-> Architect file-format contracts.

Usage:
    python tests/generate_fixtures.py
"""
import json
import os
from pathlib import Path

FIXTURES = Path(__file__).parent / "fixtures"


def write(path: str, content: str):
    full = FIXTURES / path
    full.parent.mkdir(parents=True, exist_ok=True)
    full.write_text(content)
    print(f"  + {path}")


def main():
    print("Creating fixtures...")

    # ═════════════════════════════════════════════════════════
    # SCENARIO 1: Good Architect output (3 tracks, 2 waves)
    # ═════════════════════════════════════════════════════════

    write("architect-output/tracks.md", """\
# Project Tracks

> Generated by Architect. 3 tracks across 2 waves.
> Run /conductor:implement to begin.

---

## [ ] Track: Infrastructure Scaffold
- **ID:** 01_infra_scaffold
- **Wave:** 1
- **Complexity:** M
- **Dependencies:** None

---

## [ ] Track: Authentication System
- **ID:** 02_auth_system
- **Wave:** 1
- **Complexity:** L
- **Dependencies:** None

---

## [ ] Track: Data Layer
- **ID:** 03_data_layer
- **Wave:** 2
- **Complexity:** XL
- **Dependencies:** 01_infra_scaffold

---
""")

    # ── Track 01: new, has brief ──────────────────────────
    write("architect-output/tracks/01_infra_scaffold/metadata.json", json.dumps({
        "track_id": "01_infra_scaffold",
        "status": "new",
        "complexity": "M",
        "wave": 1,
        "cc_version_at_brief": "v1.0",
        "cc_version_current": "v1.0",
        "dependencies": [],
        "interfaces_owned": ["IInfraConfig"],
        "interfaces_consumed": [],
        "patches": [],
        "created_at": "2026-02-07T12:00:00Z",
        "started_at": None,
        "completed_at": None,
    }, indent=2))

    write("architect-output/tracks/01_infra_scaffold/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 01_infra_scaffold | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-03: Environment configuration via .env files, never hardcoded
## Interfaces
Owns: IInfraConfig (database connection, redis connection, env vars)
Consumes: None (Wave 1, no upstream dependencies)
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->

# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure, Docker Compose environment,
database initialization, and CI/CD pipeline.

## Scope
IN:
- Docker Compose with PostgreSQL 16, Redis 7, and app service
- Database initialization scripts and migration framework
- Environment configuration (.env template + validation)
- CI/CD pipeline (GitHub Actions: lint, test, build)

OUT:
- Application code (handled by downstream tracks)
- Authentication (Track 02)

## Key Design Decisions
1. **Migration framework:** Alembic vs raw SQL migrations?
   Trade-off: ORM coupling vs explicit control.
2. **Docker strategy:** Single Dockerfile vs multi-stage?
   Trade-off: Build speed vs image size.
3. **CI provider:** GitHub Actions vs GitLab CI?
   Trade-off: Ecosystem integration vs self-hosting.
4. **Database pooling:** PgBouncer vs SQLAlchemy pool?
   Trade-off: External dependency vs simpler stack.

## Architectural Notes
- Track 03 depends on the database configuration this track establishes
- CI pipeline must be extensible for downstream tracks

## Complexity: M
## Estimated Phases: ~3
""")

    # ── Track 02: new, has brief ──────────────────────────
    write("architect-output/tracks/02_auth_system/metadata.json", json.dumps({
        "track_id": "02_auth_system",
        "status": "new",
        "complexity": "L",
        "wave": 1,
        "cc_version_at_brief": "v1.0",
        "cc_version_current": "v1.0",
        "dependencies": [],
        "interfaces_owned": ["IAuth"],
        "interfaces_consumed": [],
        "patches": [],
        "created_at": "2026-02-07T12:00:00Z",
        "started_at": None,
        "completed_at": None,
    }, indent=2))

    write("architect-output/tracks/02_auth_system/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 02_auth_system | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-04: JWT-based authentication for all API endpoints
## Interfaces
Owns: IAuth (login, register, token refresh)
Consumes: None
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->

# Track 02: Authentication System

## What This Track Delivers
Implements JWT-based authentication with login, registration, and token management.

## Scope
IN:
- User model and password hashing
- JWT token generation and validation
- Login and registration endpoints

OUT:
- Role-based authorization (future track)
- OAuth2 social login (future track)

## Key Design Decisions
1. **Token storage:** Stateless JWT vs server-side sessions?
   Trade-off: Scalability vs revocation.
2. **Password hashing:** bcrypt vs argon2?
   Trade-off: Compatibility vs security margin.
3. **Refresh token strategy:** Rotating vs long-lived?
   Trade-off: Security vs complexity.

## Architectural Notes
- All downstream tracks consume IAuth for protected endpoints

## Complexity: L
## Estimated Phases: ~4
""")

    # ── Track 03: new, has brief, has dependency ──────────
    write("architect-output/tracks/03_data_layer/metadata.json", json.dumps({
        "track_id": "03_data_layer",
        "status": "new",
        "complexity": "XL",
        "wave": 2,
        "cc_version_at_brief": "v1.0",
        "cc_version_current": "v1.0",
        "dependencies": ["01_infra_scaffold"],
        "interfaces_owned": ["IDataAccess"],
        "interfaces_consumed": ["IInfraConfig"],
        "patches": [],
        "created_at": "2026-02-07T12:00:00Z",
        "started_at": None,
        "completed_at": None,
    }, indent=2))

    write("architect-output/tracks/03_data_layer/brief.md", """\
<!-- ARCHITECT CONTEXT | Track: 03_data_layer | Wave: 2 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-02: Repository pattern for all data access
## Interfaces
Owns: IDataAccess
Consumes: IInfraConfig (from Track 01)
## Dependencies
01_infra_scaffold
<!-- END ARCHITECT CONTEXT -->

# Track 03: Data Layer

## What This Track Delivers
Implements the data access layer using SQLAlchemy with repository pattern.

## Scope
IN:
- SQLAlchemy model base classes
- Repository pattern implementation
- Database migration scripts

OUT:
- Specific domain models (handled by feature tracks)

## Key Design Decisions
1. **ORM style:** Declarative vs imperative mapping?
   Trade-off: Simplicity vs flexibility.
2. **Repository granularity:** One repo per model vs shared base?
   Trade-off: Type safety vs DRY.
3. **Async support:** sync SQLAlchemy vs async?
   Trade-off: Simplicity vs performance.

## Architectural Notes
- Must use the database configuration from Track 01

## Complexity: XL
## Estimated Phases: ~5
""")

    # ═════════════════════════════════════════════════════════
    # SCENARIO 2: Manual track (spec+plan, no brief)
    # ═════════════════════════════════════════════════════════

    write("conductor-manual/tracks/99_manual_track/metadata.json", json.dumps({
        "track_id": "99_manual_track",
        "status": "new",
        "complexity": "S",
        "wave": 1,
        "dependencies": [],
        "interfaces_owned": [],
        "interfaces_consumed": [],
        "patches": [],
        "created_at": "2026-02-07T14:00:00Z",
        "started_at": None,
        "completed_at": None,
    }, indent=2))

    write("conductor-manual/tracks/99_manual_track/spec.md", """\
# Track 99: Manual Track

## Functional Requirements
- FR-1: Basic CRUD operations
- FR-2: Input validation
""")

    write("conductor-manual/tracks/99_manual_track/plan.md", """\
# Track 99: Manual Track -- Implementation Plan

## Phase 1: Setup
- [ ] Task 1.1: Create module structure

## Phase 2: Implementation
- [ ] Task 2.1: Implement CRUD operations
""")

    # ═════════════════════════════════════════════════════════
    # SCENARIO 3: Post spec-gen (brief + spec, context preserved)
    # ═════════════════════════════════════════════════════════

    ctx_block = """\
<!-- ARCHITECT CONTEXT | Track: 01_infra_scaffold | Wave: 1 | CC: v1.0 -->
## Cross-Cutting Constraints
- CC-01: All services must use structured JSON logging
- CC-03: Environment configuration via .env files, never hardcoded
## Interfaces
Owns: IInfraConfig (database connection, redis connection, env vars)
Consumes: None (Wave 1, no upstream dependencies)
## Dependencies
None
<!-- END ARCHITECT CONTEXT -->"""

    write("post-spec-gen/tracks/01_infra_scaffold/brief.md", f"""\
{ctx_block}

# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure.

## Scope
IN:
- Docker Compose setup

OUT:
- Application code

## Key Design Decisions
1. **Migration framework:** Alembic vs raw SQL?

## Complexity: M
## Estimated Phases: ~3
""")

    write("post-spec-gen/tracks/01_infra_scaffold/spec.md", f"""\
{ctx_block}

# Track 01: Infrastructure Scaffold -- Specification

## Design Decisions (Resolved)
1. Migration framework: **Alembic**
2. Docker strategy: **Multi-stage**

## Functional Requirements
- FR-1: Docker Compose with PostgreSQL 16, Redis 7, app service
- FR-2: Alembic migration framework
""")

    # ═════════════════════════════════════════════════════════
    # SCENARIO 4: Bad fixtures (should FAIL validation)
    # ═════════════════════════════════════════════════════════

    # Bad: table format (old Architect output)
    write("bad/tracks_table_format.md", """\
# Track Registry

| ID | Name | Wave | Complexity | Status | Dependencies |
|----|------|------|------------|--------|-------------|
| 01_infra_scaffold | Infrastructure Scaffold | 1 | M | not started | -- |
| 02_auth_system | Authentication System | 1 | L | not started | -- |
""")

    # Bad: old metadata schema (state/NOT_STARTED)
    write("bad/metadata_old_schema.json", json.dumps({
        "track_id": "01_infra_scaffold",
        "state": "NOT_STARTED",
        "complexity": "M",
        "wave": 1,
        "dependencies": [],
        "created_at": "2026-02-07T12:00:00Z",
        "started_at": None,
        "completed_at": None,
    }, indent=2))

    # Bad: brief without ARCHITECT CONTEXT header
    write("bad/brief_no_context_header.md", """\
# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure.

## Scope
IN:
- Docker Compose setup

OUT:
- Application code

## Key Design Decisions
1. Migration framework: Alembic vs raw SQL?

## Complexity: M
## Estimated Phases: ~3
""")

    # Bad: spec with lost context header
    write("bad/spec_lost_context.md", """\
# Track 01: Infrastructure Scaffold -- Specification

## Design Decisions (Resolved)
1. Migration framework: **Alembic**

## Functional Requirements
- FR-1: Docker Compose with PostgreSQL 16
""")

    # Bad: brief with malformed context header
    write("bad/brief_malformed_context.md", """\
<!-- ARCHITECT CONTEXT -->
Some stuff here
<!-- END ARCHITECT CONTEXT -->

# Track 01: Infrastructure Scaffold

## What This Track Delivers
Sets up the foundational project structure.

## Scope
IN:
- Docker Compose setup

OUT:
- Application code

## Key Design Decisions
1. Migration framework: Alembic vs raw SQL?

## Complexity: M
## Estimated Phases: ~3
""")

    # Bad: dependency cycle (A -> B -> C -> A)
    write("bad/tracks_cycle.md", """\
# Project Tracks

> 3 tracks with circular dependency.

---

## [ ] Track: Service A
- **ID:** svc_a
- **Wave:** 1
- **Complexity:** M
- **Dependencies:** svc_c

---

## [ ] Track: Service B
- **ID:** svc_b
- **Wave:** 1
- **Complexity:** M
- **Dependencies:** svc_a

---

## [ ] Track: Service C
- **ID:** svc_c
- **Wave:** 1
- **Complexity:** M
- **Dependencies:** svc_b

---
""")

    # Bad: forward-wave dependency
    write("bad/tracks_forward_wave.md", """\
# Project Tracks

> Wave 1 track depends on Wave 2 track.

---

## [ ] Track: Early Track
- **ID:** early_track
- **Wave:** 1
- **Complexity:** M
- **Dependencies:** late_track

---

## [ ] Track: Late Track
- **ID:** late_track
- **Wave:** 2
- **Complexity:** M
- **Dependencies:** None

---
""")

    print(f"\nDone. Fixtures in {FIXTURES}")


if __name__ == "__main__":
    main()
